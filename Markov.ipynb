{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import re\n",
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "class MarkovChainTextGenerator:\n",
    "  def __init__(\n",
    "    self, order=2, token_type='word', smoothing_alpha=0.001, interpolation=True\n",
    "  ):\n",
    "    \"\"\"\n",
    "    Markov Chain Text Generator with variable order and tokenization type.\n",
    "\n",
    "    Parameters:\n",
    "        order (int): Order of the Markov chain (n-gram size)\n",
    "        token_type (str): 'word' for word-level, 'char' for character-level\n",
    "        smoothing_alpha (float): Laplace smoothing factor\n",
    "        interpolation (bool): Use backoff interpolation for unseen sequences\n",
    "    \"\"\"\n",
    "    self.order = order\n",
    "    self.token_type = token_type\n",
    "    self.smoothing_alpha = smoothing_alpha\n",
    "    self.interpolation = interpolation\n",
    "    self.ngram_counts = defaultdict(lambda: defaultdict(int))\n",
    "    self.total_counts = defaultdict(int)\n",
    "    self.vocab = set()\n",
    "\n",
    "  def tokenize(self, text):\n",
    "    \"\"\"Tokenizes text into words or characters based on user preference.\"\"\"\n",
    "    if self.token_type == 'word':\n",
    "      return re.findall(r'\\b\\w+\\b', text.lower())  # Simple word tokenization\n",
    "    elif self.token_type == 'char':\n",
    "      return list(text.lower())  # Character-level tokenization\n",
    "    else:\n",
    "      raise ValueError(\"token_type must be 'word' or 'char'\")\n",
    "\n",
    "  def train(self, corpus):\n",
    "    \"\"\"Trains the Markov chain model on a given corpus.\"\"\"\n",
    "    tokens = self.tokenize(corpus)\n",
    "    self.vocab.update(tokens)\n",
    "    self.vocab.add('<UNK>')  # Handle unknown words\n",
    "\n",
    "    for i in range(len(tokens) - self.order):\n",
    "      prefix = tuple(tokens[i : i + self.order])  # n-gram prefix\n",
    "      next_token = tokens[i + self.order]  # next token\n",
    "\n",
    "      self.ngram_counts[prefix][next_token] += 1\n",
    "      self.total_counts[prefix] += 1\n",
    "\n",
    "  def get_next_token_probs(self, prefix):\n",
    "    \"\"\"\n",
    "    Retrieves transition probabilities using interpolation.\n",
    "    \"\"\"\n",
    "    prefix = tuple(prefix)\n",
    "    if prefix in self.ngram_counts:\n",
    "      total = self.total_counts[prefix] + self.smoothing_alpha * len(self.vocab)\n",
    "      return {\n",
    "        token: (count + self.smoothing_alpha) / total\n",
    "        for token, count in self.ngram_counts[prefix].items()\n",
    "      }\n",
    "\n",
    "    # Backoff: Try shorter prefixes\n",
    "    if self.interpolation:\n",
    "      for k in range(self.order - 1, 0, -1):\n",
    "        shorter_prefix = prefix[-k:]\n",
    "        if shorter_prefix in self.ngram_counts:\n",
    "          total = self.total_counts[shorter_prefix] + self.smoothing_alpha * len(\n",
    "            self.vocab\n",
    "          )\n",
    "          return {\n",
    "            token: (count + self.smoothing_alpha) / total\n",
    "            for token, count in self.ngram_counts[shorter_prefix].items()\n",
    "          }\n",
    "\n",
    "    # If no known transitions, return uniform probabilities over vocab\n",
    "    return {token: 1 / len(self.vocab) for token in self.vocab}\n",
    "\n",
    "  def generate(self, seed=None, length=50):\n",
    "    \"\"\"\n",
    "    Generates text based on the trained model.\n",
    "    \"\"\"\n",
    "    if not self.ngram_counts:\n",
    "      raise ValueError('Model is not trained. Call `train(corpus)` first.')\n",
    "\n",
    "    tokens = (\n",
    "      list(self.tokenize(seed))\n",
    "      if seed\n",
    "      else [random.choice(list(self.vocab - {'<UNK>'}))]\n",
    "    )\n",
    "\n",
    "    while len(tokens) < length:\n",
    "      prefix = tuple(tokens[-self.order :])\n",
    "      probs = self.get_next_token_probs(prefix)\n",
    "\n",
    "      next_token = random.choices(list(probs.keys()), weights=list(probs.values()))[0]\n",
    "      tokens.append(next_token)\n",
    "\n",
    "    return ' '.join(tokens) if self.token_type == 'word' else ''.join(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'l' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 21\u001b[0m\n\u001b[1;32m     19\u001b[0m res \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m corpus:\n\u001b[0;32m---> 21\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43ml\u001b[49m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m     22\u001b[0m         l \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     23\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mNameError\u001b[0m: name 'l' is not defined"
     ]
    }
   ],
   "source": [
    "corpus = \"\"\"\n",
    "Markov chains are mathematical systems that undergo transitions from one state to another \n",
    "on a state space. A sequence of possible events in which the probability of each event \n",
    "depends only on the state attained in the previous event is called a Markov chain.\n",
    "\"\"\"\n",
    "\n",
    "corpus = \"\"\"\n",
    "Twinkle, twinkle, little star,\n",
    "How I wonder what you are!\n",
    "Up above the world so high,\n",
    "Like a diamond in the sky.\n",
    "\"\"\"\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "corpus = Path('promessi_sposi.txt').read_text()\n",
    "# corpus = Path('commedia.txt').read_text()\n",
    "\n",
    "res = [' ']\n",
    "for c in corpus:\n",
    "  l = c.lower()\n",
    "  if l == '\\n':\n",
    "    l = ' '\n",
    "  elif l in 'abcdefghijklmnopqrstuvwxyz':\n",
    "    res.append(l)\n",
    "  elif res[-1] != ' ':\n",
    "    res.append(' ')\n",
    "corpus = ''.join(res[1:])\n",
    "\n",
    "\n",
    "ORDER = 2\n",
    "generator = MarkovChainTextGenerator(\n",
    "  order=ORDER, token_type='char', smoothing_alpha=0, interpolation=False\n",
    ")\n",
    "generator.train(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'amore io a unand esere altanguitati stri pintestrotte bisvol altoccad ustamosseggio di elleggri no u'"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generator.generate('amore', length=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pygraphviz as pgv\n",
    "from IPython.display import SVG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[171], line 8\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m ts:\n\u001b[1;32m      5\u001b[0m     G\u001b[38;5;241m.\u001b[39madd_edge(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(f), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin((f \u001b[38;5;241m+\u001b[39m (t,)) [\u001b[38;5;241m-\u001b[39mORDER:]))\n\u001b[0;32m----> 8\u001b[0m SVG(\u001b[43mG\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdraw\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msvg\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprog\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdot\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m)    \n",
      "File \u001b[0;32m~/Documents/Activities/Talks/cremona-2025/.venv/lib/python3.12/site-packages/pygraphviz/agraph.py:1608\u001b[0m, in \u001b[0;36mAGraph.draw\u001b[0;34m(self, path, format, prog, args)\u001b[0m\n\u001b[1;32m   1605\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1606\u001b[0m     args \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin([args, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m-T\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mformat\u001b[39m])\n\u001b[0;32m-> 1608\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_prog\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprog\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1610\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m path \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1611\u001b[0m     fh \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_fh(path, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mw+b\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Documents/Activities/Talks/cremona-2025/.venv/lib/python3.12/site-packages/pygraphviz/agraph.py:1396\u001b[0m, in \u001b[0;36mAGraph._run_prog\u001b[0;34m(self, prog, args)\u001b[0m\n\u001b[1;32m   1393\u001b[0m child_stdin\u001b[38;5;241m.\u001b[39mclose()\n\u001b[1;32m   1395\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m threads:\n\u001b[0;32m-> 1396\u001b[0m     \u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1397\u001b[0m p\u001b[38;5;241m.\u001b[39mwait()\n\u001b[1;32m   1399\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m data:\n",
      "File \u001b[0;32m/usr/lib/python3.12/threading.py:1147\u001b[0m, in \u001b[0;36mThread.join\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1144\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcannot join current thread\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1146\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1147\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_wait_for_tstate_lock\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1148\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1149\u001b[0m     \u001b[38;5;66;03m# the behavior of a negative timeout isn't documented, but\u001b[39;00m\n\u001b[1;32m   1150\u001b[0m     \u001b[38;5;66;03m# historically .join(timeout=x) for x<0 has acted as if timeout=0\u001b[39;00m\n\u001b[1;32m   1151\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wait_for_tstate_lock(timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mmax\u001b[39m(timeout, \u001b[38;5;241m0\u001b[39m))\n",
      "File \u001b[0;32m/usr/lib/python3.12/threading.py:1167\u001b[0m, in \u001b[0;36mThread._wait_for_tstate_lock\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m   1164\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m   1166\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1167\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mlock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43mblock\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m   1168\u001b[0m         lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m   1169\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stop()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "G = pgv.AGraph(\n",
    "  directed=True, strict=True, rankdir='LR', nodesep=0.5, ranksep=0.5, ordering='out'\n",
    ")\n",
    "\n",
    "for f, ts in generator.ngram_counts.items():\n",
    "  for t in ts:\n",
    "    G.add_edge(''.join(f), ''.join((f + (t,))[-ORDER:]))\n",
    "\n",
    "\n",
    "SVG(G.draw(format='svg', prog='dot'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
